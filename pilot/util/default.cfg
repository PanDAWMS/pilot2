# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Authors:
# - Daniel Drizhuk, d.drizhuk@gmail.com, 2017
# - Paul Nilsson, paul.nilsson@cern.ch, 2017


################################
# Experiment specific paramters

[Experiment]

name: ATLAS


################################
# Pilot parameters

[Pilot]

# The default file name for the pilot log
pilotlog: pilotlog.txt

# The file name for the job definition
pandajobdata: pandaJobData.out

# Run with a fake test job, no server updates (values: 'fake', 'real'). The test job type can be 'production' or 'user'.
# The test transfer type can be 'direct' or 'NULL'. Test job command can be 'normal' or 'sleep' (normal means standard
# reconstruction job, while sleep means that the payload command is 'sleep 1' and no input or output transfers).
pandajob: real
#testjobtype: user
#testjobcommand: normal
#testtransfertype: NULL

# The URL for the PanDA server
# pandaserver: https://pandaserver.cern.ch:25443
pandaserver: https://aipanda007.cern.ch:25443

# The minimum required disk space for the pilot to run a job
free_space_limit: 5 GB

# The maximum output file size
maximum_output_file_size: 500 GB

# The maximum allowed sum of all input files (files accessed by direct access not counted bty pilot)
# (fall-back value, schedconfig value is primarily used)
maximum_input_file_sizes = 14336 MB

# The maximum number of getJob requests
maximum_getjob_requests: 2

# Looping job time limits; if job does not write anything in N hours, it is considered a looping job
looping_verifiction_time = 10
# for production jobs, 12*3600
looping_limit_default_prod: 60
#looping_limit_default_prod: 43200
# for user jobs, 3*3600
looping_limit_default_user: 10800
# The minimum allowed looping limit, 2*3600
looping_limit_min_default: 7200

# Proxy verification limit
# ..
# Proxy verification time (used by monitoring) in seconds
proxy_verification_time = 600

# The default thread check time, used by thread monitoring
thread_check: 10


################################
# Information service parameters

[Information]

# URL for the PanDA queues json
queues: http://atlas-agis-api.cern.ch/request/pandaqueue/query/list/?json

# URL for the sites json
sites: http://atlas-agis-api.cern.ch/request/site/query/list/?json

# URL for the DDM endpoints json
storages: http://atlas-agis-api.cern.ch/request/ddmendpoint/query/list/?json

# URL for the SchedConfig json
schedconfig: http://pandaserver.cern.ch:25085/cache/schedconfig

# File name for the queuedata json
queuedata: queuedata.json

# overwrite acopytools for queuedata
#acopytools: {'pr':['rucio']}
#acopytools: {'pr':['gfalcopy']}

################################
# Payload parameters

[Payload]

# File name for the job report produced by the payload
jobreport: jobReport.json

# File names for stdout/stderr
payloadstdout: payload.stdout
payloadstderr: payload.stderr


################################
# Container parameters

[Container]

# Master parameter
# Is the pilot allowed to use containers? If False, then any database settings are ignored
allow_container: False

# Name of middleware image (to be revised)
# This image is used if middleware is not found locally on the worker node. Middleware is expected to be present
# in the container image
middleware_container: middleware.img

# The setup type can be either ALRB or (explicit) singularity
setup_type: ALRB


################################
# Harvester parameters

[Harvester]

# Name of the job request file. The pilot places this file in the pilot launch directory when it wants Harvester
# to send another job (placed by Harvester in the same directory)
job_request_file: worker_requestjob.json

# Name of the kill worker file. The pilot places this file in the pilot launch directory when it has finished all jobs
# and wants Harvester to kill the worker (virtual machine)
kill_worker_file: kill_worker
